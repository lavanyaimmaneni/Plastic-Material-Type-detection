# -*- coding: utf-8 -*-
"""code_for_image_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1in_BLcgaqDUADvUgkN5ZqEed9iCIzm_1
"""

# Step 1: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Step 2: Install Ultralytics (YOLOv8)
!pip install ultralytics

"""code for predicting the labels for uploaded pics"""

# Step 1: Mount Google Drive
# from google.colab import drive
# drive.mount('/content/drive')

# # Step 2: Install ultralytics
# !pip install ultralytics

# Step 3: Import required libraries
from ultralytics import YOLO
import os
from IPython.display import Image, display
from google.colab import files

# Step 4: Set paths
model_path = '/content/drive/MyDrive/yolo1/plastic_detection_results/weights/best.pt'
output_dir = '/content/drive/MyDrive/yolo1/plastic_detection_results/inference_results'
os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist

# Step 5: Load the model
model = YOLO(model_path)

# Step 6: Upload or specify input images
uploaded = files.upload()  # Upload images manually (e.g., image1.jpg, image2.jpg)

# Step 7: Run inference on uploaded images and display results
for filename in uploaded.keys():
    # Run inference
    results = model.predict(
        source=filename,
        conf=0.25,        # Confidence threshold
        iou=0.45,         # IoU threshold
        save=True,        # Save results
        save_txt=True,    # Save predictions as .txt
        project=output_dir,
        name='image_predictions',
        exist_ok=True
    )
    print(f"Inference completed for {filename}. Results saved in {output_dir}/image_predictions/")

    # Get the path to the annotated image (YOLO saves it with the same name in the output directory)
    annotated_image_path = os.path.join(output_dir, 'image_predictions', f"{os.path.splitext(filename)[0]}.jpg")

    # Display the annotated image
    if os.path.exists(annotated_image_path):
        display(Image(filename=annotated_image_path))
    else:
        print(f"Annotated image not found at {annotated_image_path}. Check the output directory.")

# # Step 1: Mount Google Drive
# from google.colab import drive
# drive.mount('/content/drive')

# # Step 2: Install required libraries
# !pip install ultralytics opencv-python-headless

# Step 3: Import required libraries
from ultralytics import YOLO
import cv2
import numpy as np
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
import os

# Step 4: Set paths
model_path = '/content/drive/MyDrive/yolo1/plastic_detection_results/weights/best.pt'
output_dir = '/content/drive/MyDrive/yolo1/plastic_detection_results/video_inference_results'
os.makedirs(output_dir, exist_ok=True)

# Step 5: Load the model
model = YOLO(model_path)

# Step 6: JavaScript to access webcam
def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const capture = document.createElement('button');
            capture.textContent = 'Start/Stop Capture';
            div.appendChild(capture);

            const video = document.createElement('video');
            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({video: true});

            document.body.appendChild(div);
            div.appendChild(video);
            video.srcObject = stream;
            await video.play();

            // Resize the output to fit the video element.
            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

            // Wait for Capture to be clicked
            await new Promise((resolve) => capture.onclick = resolve);

            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            stream.getTracks().forEach(track => track.stop());
            div.remove();
            return canvas.toDataURL('image/jpeg', quality);
        }
        ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

# Step 7: Function to process and predict
def predict_from_webcam():
    while True:
        try:
            # Capture frame from webcam
            img_path = take_photo()
            print(f"Captured image saved as {img_path}")

            # Read the image with OpenCV
            img = cv2.imread(img_path)
            if img is None:
                print("Failed to load image. Retrying...")
                continue

            # Run YOLOv8 prediction
            results = model.predict(
                source=img,
                conf=0.25,        # Confidence threshold
                iou=0.45,         # IoU threshold
                save=True,        # Save results
                save_txt=True,    # Save predictions as .txt
                project=output_dir,
                name='webcam_predictions',
                exist_ok=True
            )
            print(f"Inference completed for {img_path}")

            # Get the annotated image path
            annotated_image_path = os.path.join(output_dir, 'webcam_predictions', f"{os.path.splitext(os.path.basename(img_path))[0]}.jpg")

            # Display the annotated image
            if os.path.exists(annotated_image_path):
                display(Image(filename=annotated_image_path))
            else:
                print(f"Annotated image not found at {annotated_image_path}")

            # Optional: Remove the temporary input image
            os.remove(img_path)

        except Exception as e:
            print(f"An error occurred: {e}")
            break

# Step 8: Run the prediction loop
print("Click the 'Start/Stop Capture' button in the cell below to begin. Click again to stop and process the next frame.")
predict_from_webcam()

# # Step 1: Mount Google Drive
# from google.colab import drive
# drive.mount('/content/drive')

# # Step 2: Install required libraries
# !pip install ultralytics opencv-python-headless

# Step 3: Import required libraries
from ultralytics import YOLO
import cv2
import numpy as np
from IPython.display import display, Image
import os
from google.colab.patches import cv2_imshow  # For displaying OpenCV images in Colab
from google.colab import files

# Step 4: Set paths
model_path = '/content/drive/MyDrive/yolo1/plastic_detection_results/weights/best.pt'
output_dir = '/content/drive/MyDrive/yolo1/plastic_detection_results/video_inference_results'
os.makedirs(output_dir, exist_ok=True)

# Step 5: Load the model
model = YOLO(model_path)

# Step 6: Upload or specify video file
print("Please upload your video file (e.g., .mp4):")
uploaded = files.upload()
video_path = list(uploaded.keys())[0]  # Get the name of the uploaded video
print(f"Processing video: {video_path}")

# Alternatively, use a video from Drive
# video_path = '/content/drive/MyDrive/yolo1/your_video_folder/video.mp4'  # Uncomment and set path if using Drive video

# Step 7: Open the video
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("Error: Could not open video.")
    exit()

# Get video properties
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Step 8: Process video frames continuously
frame_count = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("Video processing completed or error occurred.")
        break

    # Run YOLOv8 prediction on the frame
    results = model.predict(
        source=frame,
        conf=0.25,        # Confidence threshold
        iou=0.45,         # IoU threshold
        verbose=False     # Suppress detailed output
    )

    # Get the annotated frame (first result)
    annotated_frame = results[0].plot()  # Draws bounding boxes on the frame

    # Display the annotated frame in Colab
    cv2_imshow(annotated_frame)

    # Save the annotated frame (optional)
    output_frame_path = os.path.join(output_dir, f'frame_{frame_count:06d}.jpg')
    cv2.imwrite(output_frame_path, annotated_frame)
    print(f"Saved frame {frame_count} to {output_frame_path}")

    frame_count += 1

    # Optional: Add a small delay to control frame rate (e.g., match video FPS)
    # import time
    # time.sleep(1 / fps)  # Uncomment to approximate real-time display

# Release the video capture object
cap.release()
print(f"Processed {frame_count} frames. Results saved in {output_dir}.")

# # Step 1: Mount Google Drive
# from google.colab import drive
# drive.mount('/content/drive')

# # Step 2: Install required libraries
# !pip install ultralytics opencv-python-headless

# Step 3: Import required libraries
from ultralytics import YOLO
import cv2
import numpy as np
from IPython.display import display, Javascript, Image
from google.colab.output import eval_js
from base64 import b64decode
import os

# Step 4: Set paths
model_path = '/content/drive/MyDrive/yolo1/plastic_detection_results/weights/best.pt'
output_dir = '/content/drive/MyDrive/yolo1/plastic_detection_results/webcam_inference_results'
os.makedirs(output_dir, exist_ok=True)

# Step 5: Load the model
model = YOLO(model_path)

# Step 6: JavaScript to access webcam
def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const capture = document.createElement('button');
            capture.textContent = 'Capture Frame';
            div.appendChild(capture);

            const video = document.createElement('video');
            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({video: true});

            document.body.appendChild(div);
            div.appendChild(video);
            video.srcObject = stream;
            await video.play();

            // Resize the output to fit the video element.
            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

            // Wait for Capture to be clicked
            let image_data;
            capture.onclick = () => {
                const canvas = document.createElement('canvas');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                canvas.getContext('2d').drawImage(video, 0, 0);
                image_data = canvas.toDataURL('image/jpeg', quality);
                stream.getTracks().forEach(track => track.stop());
                div.remove();
            };
            return new Promise(resolve => {
                const check = setInterval(() => {
                    if (image_data) {
                        clearInterval(check);
                        resolve(image_data);
                    }
                }, 100);
            });
        }
        ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

# Step 7: Function to process and predict
def predict_from_webcam():
    frame_count = 0
    print("Click the 'Capture Frame' button to capture and process a frame. Stop the cell to end.")
    while True:
        try:
            # Capture frame from webcam
            img_path = take_photo(f'frame_{frame_count:06d}.jpg')
            print(f"Captured frame {frame_count} saved as {img_path}")

            # Read the image with OpenCV
            img = cv2.imread(img_path)
            if img is None:
                print("Failed to load image. Retrying...")
                continue

            # Run YOLOv8 prediction
            results = model.predict(
                source=img,
                conf=0.25,        # Confidence threshold
                iou=0.45,         # IoU threshold
                save=True,        # Save results
                save_txt=True,    # Save predictions as .txt
                project=output_dir,
                name='webcam_predictions',
                exist_ok=True
            )
            print(f"Inference completed for frame {frame_count}")

            # Get the annotated image path
            annotated_image_path = os.path.join(output_dir, 'webcam_predictions', f"frame_{frame_count:06d}.jpg")

            # Display the annotated image
            if os.path.exists(annotated_image_path):
                display(Image(filename=annotated_image_path))
            else:
                print(f"Annotated image not found at {annotated_image_path}")

            # Remove the temporary input image
            os.remove(img_path)

            frame_count += 1

        except Exception as e:
            print(f"An error occurred: {e}")
            break

# Step 8: Run the prediction loop
predict_from_webcam()

